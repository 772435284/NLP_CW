model_name: 'bert-base-uncased'
MAX_SEQ_LEN: 256
learning_rate: 5E-6
logging_steps: 100
eval_steps: 400
per_device_train_batch_size: 12
per_device_eval_batch_size: 12
num_train_epochs: 20
evaluation_strategy: "steps"