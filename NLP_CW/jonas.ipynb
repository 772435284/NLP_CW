{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.21.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.8/dist-packages (1.3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting beautifulsoup4\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/69/bf/f0f194d3379d3f3347478bd267f754fc68c11cbf2fe302a6ab69447b1417/beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 281 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/72/a6/fd01694427f1c3fcadfdc5f1de901b813b9ac756f0806ef470cfed1de281/soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "! python -m pip install nltk\n",
    "! python -m pip install wordcloud\n",
    "! python -m pip install Unidecode\n",
    "! python -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting contractions\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/76/e3/04c8468a0e16304477fe688134344c175732b2bd8886f184170ef3579611/contractions-0.1.66-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting anyascii\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6d/7b/19437c9a5bd16e1bb3a5bf43f7655e341882befceae0122e43c8e2c21e1e/anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/d8/99fe14486594aadf431fbef6853e3c8731feeac3f4f013ea0ed055197d12/pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.0 contractions-0.1.66 pyahocorasick-1.4.4 textsearch-0.0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "from dpm_preprocessing import DPMProprocessed\n",
    "import torch\n",
    "#from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments, RobertaConfig\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "#model_name = 'roberta-base'\n",
    "model_name = 'bert-base-uncased'\n",
    "model_path = f'./models/pcl_{model_name}_finetuned/model/'\n",
    "tokenizer_path = f'./models/pcl_{model_name}_finetuned/tokenizer/'\n",
    "MAX_SEQ_LEN = 256\n",
    "\n",
    "WORKING_ENV = 'SERVER' # Can be JONAS, SERVER\n",
    "assert WORKING_ENV in ['JONAS', 'SERVER']\n",
    "\n",
    "if WORKING_ENV == 'SERVER':\n",
    "    temp_model_path = f'/hy-tmp/pcl/{model_name}/'\n",
    "if WORKING_ENV == 'JONAS': \n",
    "    temp_model_path = f'./experiment/pcl/{model_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, input_set):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = list(input_set['text'])\n",
    "        self.labels = list(input_set['label'])\n",
    "        \n",
    "    def collate_fn(self, batch):\n",
    "\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for b in batch:\n",
    "            texts.append(b['text'])\n",
    "            labels.append(b['label'])\n",
    "\n",
    "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=MAX_SEQ_LEN)\n",
    "        encodings['labels'] =  torch.tensor(labels)\n",
    "        return encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        item = {'text': self.texts[idx],\n",
    "                'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d498f778b6409cb99db99f8b4770d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7ef13ab7a74d5bb12f91a5fe19f40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dfea30a9974ad39f3b11fbe74f2847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa01dd770e4b90beb1ea70430348f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c156528520ec4ce186092515c71db349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name , config = config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map of label to numerical label:\n",
      "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n",
      "      par_id      art_id     keyword country  \\\n",
      "0          1  @@24942188    hopeless      ph   \n",
      "1          2  @@21968160     migrant      gh   \n",
      "2          3  @@16584954   immigrant      ie   \n",
      "3          4   @@7811231    disabled      nz   \n",
      "4          5   @@1494111     refugee      ca   \n",
      "...      ...         ...         ...     ...   \n",
      "10464  10465  @@14297363       women      lk   \n",
      "10465  10466  @@70091353  vulnerable      ph   \n",
      "10466  10467  @@20282330     in-need      ng   \n",
      "10467  10468  @@16753236    hopeless      in   \n",
      "10468  10469  @@16779383    homeless      ie   \n",
      "\n",
      "                                                    text  label orig_label  \\\n",
      "0      We are living in times of absolute insanity , ...      0          0   \n",
      "1      In Libya today , there are countless number of...      0          0   \n",
      "2       White House press secretary Sean Spicer said ...      0          0   \n",
      "3      Council customers only signs would be displaye...      0          0   \n",
      "4       Just like we received migrants fleeing El Sal...      0          0   \n",
      "...                                                  ...    ...        ...   \n",
      "10464   Sri Lankan norms and culture inhibit women fr...      0          1   \n",
      "10465  He added that the AFP will continue to bank on...      0          0   \n",
      "10466   She has one huge platform , and information c...      1          3   \n",
      "10467   Anja Ringgren Loven I ca n't find a word to d...      1          4   \n",
      "10468   Guinness World Record of 540lbs of 7 layer mu...      1          3   \n",
      "\n",
      "       lenght  \n",
      "0         123  \n",
      "1          41  \n",
      "2          25  \n",
      "3          30  \n",
      "4          51  \n",
      "...       ...  \n",
      "10464      62  \n",
      "10465      42  \n",
      "10466      54  \n",
      "10467     103  \n",
      "10468      29  \n",
      "\n",
      "[10469 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'augment_substitute_with_context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38082/825008780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traindf.pickle'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valdf.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# train_df, val_df = dpm_pp.get_unbalanced_split(0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpm_pp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_oversampled_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traindf.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valdf.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/neal/NLP_CW/NLP_CW/dpm_preprocessing.py\u001b[0m in \u001b[0;36mget_oversampled_split\u001b[0;34m(self, oversampling_ratio, val_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moversampling_ratio\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mnew_sampled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mnew_sampled_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sampled_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugment_substitute_with_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mto_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sampled_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'augment_substitute_with_context' is not defined"
     ]
    }
   ],
   "source": [
    "dpm_pp = DPMProprocessed('.', 'task4_test.tsv')\n",
    "\n",
    "if not os.path.isfile('traindf.pickle') or not os.path.isfile('valdf.pickle'):\n",
    "  # train_df, val_df = dpm_pp.get_unbalanced_split(0.1)\n",
    "  train_df, val_df = dpm_pp.get_oversampled_split(val_size=0.1)\n",
    "  train_df.to_pickle('traindf.pickle')\n",
    "  val_df.to_pickle('valdf.pickle')\n",
    "else:\n",
    "  train_df = pd.read_pickle('traindf.pickle')\n",
    "  val_df = pd.read_pickle('valdf.pickle')\n",
    "\n",
    "print(\"Training set length: \",len(train_df))\n",
    "print(\"Validation set length: \",len(val_df))\n",
    "\n",
    "train_dataset = PCLDataset(tokenizer, train_df)\n",
    "eval_dataset = PCLDataset(tokenizer, val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        weight_scale = len(val_df)/len(train_df)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, weight_scale]).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return ((loss, outputs) if return_outputs else loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9422\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15720' max='15720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15720/15720 23:35, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.626008</td>\n",
       "      <td>0.668513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.493076</td>\n",
       "      <td>0.732259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.451532</td>\n",
       "      <td>0.705537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.639005</td>\n",
       "      <td>0.740314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.691594</td>\n",
       "      <td>0.738676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.732228</td>\n",
       "      <td>0.728574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.681236</td>\n",
       "      <td>0.743088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.747057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.832007</td>\n",
       "      <td>0.717084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>1.289713</td>\n",
       "      <td>0.718661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>1.169875</td>\n",
       "      <td>0.724183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>1.409692</td>\n",
       "      <td>0.711425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>1.259009</td>\n",
       "      <td>0.731583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>1.410611</td>\n",
       "      <td>0.719029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>1.457206</td>\n",
       "      <td>0.721103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>1.446207</td>\n",
       "      <td>0.718073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.455920</td>\n",
       "      <td>0.719487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.673276</td>\n",
       "      <td>0.730498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>1.856378</td>\n",
       "      <td>0.718787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>1.846197</td>\n",
       "      <td>0.720411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.857996</td>\n",
       "      <td>0.722158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>2.054029</td>\n",
       "      <td>0.717942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.965989</td>\n",
       "      <td>0.729844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.046610</td>\n",
       "      <td>0.727059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>2.075146</td>\n",
       "      <td>0.723705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>2.025382</td>\n",
       "      <td>0.719029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>2.193655</td>\n",
       "      <td>0.732211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>2.051573</td>\n",
       "      <td>0.718554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.950804</td>\n",
       "      <td>0.732259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>2.087492</td>\n",
       "      <td>0.721569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.829216</td>\n",
       "      <td>0.734555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.058047</td>\n",
       "      <td>0.737870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.183217</td>\n",
       "      <td>0.733544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.131556</td>\n",
       "      <td>0.723192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.960353</td>\n",
       "      <td>0.733104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.133852</td>\n",
       "      <td>0.728899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>2.266873</td>\n",
       "      <td>0.731875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.229203</td>\n",
       "      <td>0.728579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>2.213490</td>\n",
       "      <td>0.731185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-1000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-1000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-1500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-1500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-2000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-2000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-2500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-2500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-3000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-3000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-3500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-3500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-4000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-4000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-4500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-4500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-5000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-5000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-5500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-5500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-6000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-6000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-6500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-6500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-7000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-7000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-7500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-7500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-8000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-8000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-8500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-8500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-9000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-9000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-9500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-9500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-9500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-10000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-10000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-10500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-10500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-10500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-11000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-11000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-11000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-11500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-11500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-12000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-12000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-12000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-12500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-12500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-12500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-13000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-13000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-13500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-13500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-13500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-14000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-14000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-14000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-14500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-14500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-14500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-15000\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-15000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-15000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "Saving model checkpoint to /hy-tmp/pcl/bert-base-uncased/checkpoint-15500\n",
      "Configuration saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-15500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/bert-base-uncased/checkpoint-15500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 12\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15720, training_loss=0.12956529954205737, metrics={'train_runtime': 1415.4088, 'train_samples_per_second': 133.135, 'train_steps_per_second': 11.106, 'total_flos': 1.11150854225808e+16, 'train_loss': 0.12956529954205737, 'epoch': 20.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loader = DataLoader(eval_dataset)\n",
    "def compute_metric_eval(arg):\n",
    "    logits, labels_gold = arg[0], arg[1]\n",
    "    labels_pred = np.argmax(logits, axis = 1)\n",
    "    return {'f1_macro' :f1_score(labels_gold, labels_pred, average='macro') } #more metrics can be added\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=temp_model_path,\n",
    "        learning_rate = 5e-6,\n",
    "        logging_steps= 100,\n",
    "        eval_steps = 400,\n",
    "        per_device_train_batch_size=12,\n",
    "        per_device_eval_batch_size = 12,\n",
    "        num_train_epochs = 20,\n",
    "        evaluation_strategy= \"steps\"\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        model=model,                         \n",
    "        args=training_args,                 \n",
    "        train_dataset=train_dataset,                   \n",
    "        data_collator=eval_dataset.collate_fn,\n",
    "        compute_metrics = compute_metric_eval,\n",
    "        eval_dataset = eval_dataset\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/pcl_bert-base-uncased_finetuned/model/\n",
      "Configuration saved in ./models/pcl_bert-base-uncased_finetuned/model/config.json\n",
      "Model weights saved in ./models/pcl_bert-base-uncased_finetuned/model/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/pcl_bert-base-uncased_finetuned/tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ./models/pcl_bert-base-uncased_finetuned/tokenizer/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "train_df.to_pickle('train_df.pickle')\n",
    "val_df.to_pickle('val_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Didn't find file ./models/pcl_bert-base-uncased_finetuned/tokenizer/added_tokens.json. We won't load it.\n",
      "loading file ./models/pcl_bert-base-uncased_finetuned/tokenizer/vocab.txt\n",
      "loading file ./models/pcl_bert-base-uncased_finetuned/tokenizer/tokenizer.json\n",
      "loading file None\n",
      "loading file ./models/pcl_bert-base-uncased_finetuned/tokenizer/special_tokens_map.json\n",
      "loading file ./models/pcl_bert-base-uncased_finetuned/tokenizer/tokenizer_config.json\n",
      "loading weights file ./models/pcl_bert-base-uncased_finetuned/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./models/pcl_bert-base-uncased_finetuned/model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path , config = config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_pickle('train_df.pickle')\n",
    "val_df = pd.read_pickle('val_df.pickle')\n",
    "\n",
    "train_dataset = PCLDataset(tokenizer, train_df)\n",
    "eval_dataset = PCLDataset(tokenizer, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pcl(input, tokenizer, model): \n",
    "  model.eval()\n",
    "  encodings = tokenizer(input, return_tensors='pt', padding=True, truncation=True, max_length=256)\n",
    "  encodings = encodings.to(device)\n",
    "  output = model(**encodings)\n",
    "  logits = output.logits\n",
    "  preds = torch.max(logits, 1)\n",
    "\n",
    "  return {'prediction':preds[1], 'confidence':preds[0]}\n",
    "\n",
    "def evaluate(model, tokenizer, data_loader):\n",
    "\n",
    "  preds = []\n",
    "  tot_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data in (data_loader): \n",
    "\n",
    "      labels = {}\n",
    "      labels['label'] = data['label']\n",
    "\n",
    "      tweets = data['text']\n",
    "\n",
    "      pred = predict_pcl(tweets, tokenizer, model)\n",
    "\n",
    "      preds.append(np.array(pred['prediction'].cpu()))\n",
    "      tot_labels.append(np.array(labels['label'].cpu()))\n",
    "\n",
    "  # with the saved predictions and labels we can compute accuracy, precision, recall and f1-score\n",
    "  \n",
    "\n",
    "  return preds, tot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not PCL': {'precision': 0.9467640918580376, 'recall': 0.9567510548523207, 'f1-score': 0.9517313746065059, 'support': 948}, 'PCL': {'precision': 0.5393258426966292, 'recall': 0.48484848484848486, 'f1-score': 0.5106382978723405, 'support': 99}, 'accuracy': 0.9121298949379179, 'macro avg': {'precision': 0.7430449672773334, 'recall': 0.7207997698504027, 'f1-score': 0.7311848362394232, 'support': 1047}, 'weighted avg': {'precision': 0.9082384121379045, 'recall': 0.9121298949379179, 'f1-score': 0.9100234332534186, 'support': 1047}}\n",
      "0.9121298949379179\n",
      "0.9517313746065059\n",
      "0.5106382978723405\n"
     ]
    }
   ],
   "source": [
    "validation_loader = DataLoader(eval_dataset)\n",
    "\n",
    "preds, tot_labels = evaluate(model, tokenizer, validation_loader)\n",
    "tot_labels = np.array(tot_labels)\n",
    "preds = np.array(preds)\n",
    "report = classification_report(tot_labels, preds, target_names=[\"Not PCL\",\"PCL\"], output_dict= True)\n",
    "print(report)\n",
    "\n",
    "print(report['accuracy'])\n",
    "print(report['Not PCL']['f1-score'])\n",
    "print(report['PCL']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm_pp.load_test()\n",
    "test_df = dpm_pp.test_set_df\n",
    "test_df['label'] = 0\n",
    "test_dataset = PCLDataset(tokenizer, test_df)\n",
    "\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "preds, tot_labels = evaluate(model, tokenizer, test_loader)\n",
    "tot_labels = np.array(tot_labels)\n",
    "preds = np.array(preds)\n",
    "# report = classification_report(tot_labels, preds, target_names=[\"Not PCL\",\"PCL\"], output_dict= True)\n",
    "# print(report)\n",
    "\n",
    "# print(report['accuracy'])\n",
    "# print(report['Not PCL']['f1-score'])\n",
    "# print(report['PCL']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3832, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds.shape\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3560, 1: 272})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "preds = preds.reshape(-1)\n",
    "Counter(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "\twith open(outf_path,'w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  adding: task1.txt (deflated 95%)\n"
     ]
    }
   ],
   "source": [
    "labels2file([[k] for k in preds], 'task1.txt')\n",
    "!cat task1.txt | head -n 10\n",
    "!zip submission.zip task1.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
