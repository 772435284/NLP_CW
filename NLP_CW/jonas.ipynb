{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.62.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.8/dist-packages (1.3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4) (2.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "! python -m pip install nltk\n",
    "! python -m pip install wordcloud\n",
    "! python -m pip install Unidecode\n",
    "! python -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.66)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.8/dist-packages (1.1.10)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.21.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.26.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.22.0->nlpaug) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.22.0->nlpaug) (1.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dpm_preprocessing import DPMProprocessed\n",
    "import torch\n",
    "#from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments, RobertaConfig\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "model_name = \"microsoft/deberta-v2-xlarge\"\n",
    "assert model_name in ['roberta-base', 'bert-base-uncased', 'google/electra-small-discriminator', \"microsoft/deberta-v2-xlarge\"]\n",
    "\n",
    "model_path = f'./models/pcl_{model_name}_finetuned/model/'\n",
    "tokenizer_path = f'./models/pcl_{model_name}_finetuned/tokenizer/'\n",
    "MAX_SEQ_LEN = 256\n",
    "\n",
    "WORKING_ENV = 'SERVER' #Â Can be JONAS, SERVER\n",
    "assert WORKING_ENV in ['JONAS', 'SERVER']\n",
    "\n",
    "if WORKING_ENV == 'SERVER':\n",
    "    temp_model_path = f'/hy-tmp/pcl/{model_name}/'\n",
    "if WORKING_ENV == 'JONAS': \n",
    "    temp_model_path = f'./experiment/pcl/{model_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, input_set):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = list(input_set['text'])\n",
    "        self.labels = list(input_set['label'])\n",
    "        \n",
    "    def collate_fn(self, batch):\n",
    "\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for b in batch:\n",
    "            texts.append(b['text'])\n",
    "            labels.append(b['label'])\n",
    "\n",
    "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=MAX_SEQ_LEN)\n",
    "        encodings['labels'] =  torch.tensor(labels)\n",
    "        return encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        item = {'text': self.texts[idx],\n",
    "                'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name , config = config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map of label to numerical label:\n",
      "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n",
      "      par_id      art_id     keyword country  \\\n",
      "0          1  @@24942188    hopeless      ph   \n",
      "1          2  @@21968160     migrant      gh   \n",
      "2          3  @@16584954   immigrant      ie   \n",
      "3          4   @@7811231    disabled      nz   \n",
      "4          5   @@1494111     refugee      ca   \n",
      "...      ...         ...         ...     ...   \n",
      "10464  10465  @@14297363       women      lk   \n",
      "10465  10466  @@70091353  vulnerable      ph   \n",
      "10466  10467  @@20282330     in-need      ng   \n",
      "10467  10468  @@16753236    hopeless      in   \n",
      "10468  10469  @@16779383    homeless      ie   \n",
      "\n",
      "                                                    text  label orig_label  \\\n",
      "0      We are living in times of absolute insanity , ...      0          0   \n",
      "1      In Libya today , there are countless number of...      0          0   \n",
      "2       White House press secretary Sean Spicer said ...      0          0   \n",
      "3      Council customers only signs would be displaye...      0          0   \n",
      "4       Just like we received migrants fleeing El Sal...      0          0   \n",
      "...                                                  ...    ...        ...   \n",
      "10464   Sri Lankan norms and culture inhibit women fr...      0          1   \n",
      "10465  He added that the AFP will continue to bank on...      0          0   \n",
      "10466   She has one huge platform , and information c...      1          3   \n",
      "10467   Anja Ringgren Loven I ca n't find a word to d...      1          4   \n",
      "10468   Guinness World Record of 540lbs of 7 layer mu...      1          3   \n",
      "\n",
      "       lenght  \n",
      "0         123  \n",
      "1          41  \n",
      "2          25  \n",
      "3          30  \n",
      "4          51  \n",
      "...       ...  \n",
      "10464      62  \n",
      "10465      42  \n",
      "10466      54  \n",
      "10467     103  \n",
      "10468      29  \n",
      "\n",
      "[10469 rows x 8 columns]\n",
      "Training set length:  9422\n",
      "Validation set length:  1047\n"
     ]
    }
   ],
   "source": [
    "dpm_pp = DPMProprocessed('.', 'task4_test.tsv')\n",
    "\n",
    "\n",
    "df_type = 'UNBALANCED' #Â Can be UNBALANCED, BACKTRANS, OVERSAMPLING\n",
    "assert df_type in ['UNBALANCED', 'BACKTRANS', 'OVERSAMPLING']\n",
    "\n",
    "if df_type == 'UNBALANCED':\n",
    "    train_df_path = 'traindf.pickle'\n",
    "    val_df_path = 'valdf.pickle'\n",
    "if df_type == 'BACKTRANS': \n",
    "    train_df_path = 'traindf_backtrans.pickle'\n",
    "    val_df_path = 'valdf_backtrans.pickle'\n",
    "\n",
    "\n",
    "if not os.path.isfile(train_df_path) or not os.path.isfile(val_df_path):\n",
    "  train_df, val_df = dpm_pp.get_unbalanced_split(0.1)\n",
    "  train_df.to_pickle('traindf.pickle')\n",
    "  val_df.to_pickle('valdf.pickle')\n",
    "else:\n",
    "  train_df = pd.read_pickle(train_df_path)\n",
    "  val_df = pd.read_pickle(val_df_path)\n",
    "\n",
    "print(\"Training set length: \",len(train_df))\n",
    "print(\"Validation set length: \",len(val_df))\n",
    "\n",
    "train_dataset = PCLDataset(tokenizer, train_df)\n",
    "eval_dataset = PCLDataset(tokenizer, val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # weight_scale = len(train_df[train_df['label']==0])/len(train_df[train_df['label']==1])\n",
    "        weight_scale = 1\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, weight_scale]).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return ((loss, outputs) if return_outputs else loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9422\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9424' max='9424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9424/9424 1:07:23, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Pcl F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.488882</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.345728</td>\n",
       "      <td>0.609677</td>\n",
       "      <td>0.264463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.322935</td>\n",
       "      <td>0.681084</td>\n",
       "      <td>0.402985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>0.352524</td>\n",
       "      <td>0.722139</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.342364</td>\n",
       "      <td>0.748465</td>\n",
       "      <td>0.538012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.321558</td>\n",
       "      <td>0.739493</td>\n",
       "      <td>0.516556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.340478</td>\n",
       "      <td>0.714841</td>\n",
       "      <td>0.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.314339</td>\n",
       "      <td>0.752659</td>\n",
       "      <td>0.541935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.346711</td>\n",
       "      <td>0.789387</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.345060</td>\n",
       "      <td>0.773494</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.347241</td>\n",
       "      <td>0.782328</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.373592</td>\n",
       "      <td>0.793585</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.784373</td>\n",
       "      <td>0.603550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.349584</td>\n",
       "      <td>0.803585</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.383679</td>\n",
       "      <td>0.788731</td>\n",
       "      <td>0.611765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.359292</td>\n",
       "      <td>0.801521</td>\n",
       "      <td>0.635838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.363225</td>\n",
       "      <td>0.803585</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8500\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8500/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1047\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-9000\n",
      "Configuration saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-9000/config.json\n",
      "Model weights saved in /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-9000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /hy-tmp/pcl/microsoft/deberta-v2-xlarge/checkpoint-7500 (score: 0.64).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9424, training_loss=0.2959647667175238, metrics={'train_runtime': 4043.662, 'train_samples_per_second': 9.32, 'train_steps_per_second': 2.331, 'total_flos': 1.2884359771641792e+16, 'train_loss': 0.2959647667175238, 'epoch': 4.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loader = DataLoader(eval_dataset)\n",
    "def compute_metric_eval(arg):\n",
    "    logits, labels_gold = arg[0], arg[1]\n",
    "    labels_pred = np.argmax(logits, axis = 1)\n",
    "    return {'f1_macro' :f1_score(labels_gold, labels_pred, average='macro'), \n",
    "            'pcl_f1': classification_report(labels_gold, labels_pred, target_names=[\"Not PCL\",\"PCL\"], output_dict= True)['PCL']['f1-score']} #more metrics can be added\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=temp_model_path,\n",
    "        learning_rate = 1e-6,\n",
    "        logging_steps= 100,\n",
    "        eval_steps = 500,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size = 4,\n",
    "        num_train_epochs = 4,\n",
    "        evaluation_strategy= \"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='pcl_f1'\n",
    "        )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        model=model,                         \n",
    "        args=training_args,                 \n",
    "        train_dataset=train_dataset,                   \n",
    "        data_collator=eval_dataset.collate_fn,\n",
    "        compute_metrics = compute_metric_eval,\n",
    "        eval_dataset = eval_dataset\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/model/\n",
      "Configuration saved in ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/model/config.json\n",
      "Model weights saved in ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/model/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/special_tokens_map.json\n",
      "added tokens file saved in ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "train_df.to_pickle('train_df.pickle')\n",
    "val_df.to_pickle('val_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v2-xlarge/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9b1521087cc24b2b8011f3a1ed13d4adfedc3c0668198e49f5cd0fbac08c1390.68c59ec99ca9b4a368c8bc9f42e06b33f4766cb50174c88e8000ed1880fa4d3a\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v2-xlarge\",\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Didn't find file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/tokenizer.json. We won't load it.\n",
      "loading file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/spm.model\n",
      "loading file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/added_tokens.json\n",
      "loading file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/special_tokens_map.json\n",
      "loading file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/tokenizer/tokenizer_config.json\n",
      "loading file None\n",
      "Adding [MASK] to the vocabulary\n",
      "loading weights file ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models/pcl_microsoft/deberta-v2-xlarge_finetuned/model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path , config = config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_pickle('train_df.pickle')\n",
    "val_df = pd.read_pickle('val_df.pickle')\n",
    "\n",
    "train_dataset = PCLDataset(tokenizer, train_df)\n",
    "eval_dataset = PCLDataset(tokenizer, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pcl(input, tokenizer, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    encodings = tokenizer(input, return_tensors='pt', padding=True, truncation=True, max_length=256)\n",
    "    encodings = encodings.to(device)\n",
    "    output = model(**encodings)\n",
    "    logits = output.logits\n",
    "    prob = nn.functional.softmax(logits)[: , 1].cpu()\n",
    "    preds = np.array([int(prob>threshold)])\n",
    "    return {'prediction': preds, 'confidence': prob}\n",
    "\n",
    "\n",
    "def evaluate(model, tokenizer, data_loader, threshold=0.5):\n",
    "    preds = []\n",
    "    tot_labels = []\n",
    "    confidences = []\n",
    "    with torch.no_grad():\n",
    "        for data in (data_loader):\n",
    "            labels = {}\n",
    "            labels['label'] = data['label']\n",
    "\n",
    "            tweets = data['text']\n",
    "\n",
    "            pred = predict_pcl(tweets, tokenizer, model, threshold)\n",
    "\n",
    "            preds.append(np.array(pred['prediction']))\n",
    "            tot_labels.append(np.array(labels['label'].cpu()))\n",
    "            confidences.append(np.array(pred['confidence'].cpu()))\n",
    "\n",
    "    # with the saved predictions and labels we can compute accuracy, precision, recall and f1-score\n",
    "\n",
    "    return preds, tot_labels, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760/1932561778.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = nn.functional.softmax(logits)[: , 1].cpu()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not PCL': {'precision': 0.9557157569515963, 'recall': 0.9789029535864979, 'f1-score': 0.9671704012506515, 'support': 948}, 'PCL': {'precision': 0.7368421052631579, 'recall': 0.5656565656565656, 'f1-score': 0.64, 'support': 99}, 'accuracy': 0.9398280802292264, 'macro avg': {'precision': 0.8462789311073771, 'recall': 0.7722797596215318, 'f1-score': 0.8035852006253257, 'support': 1047}, 'weighted avg': {'precision': 0.9350199675369302, 'recall': 0.9398280802292264, 'f1-score': 0.9362345180378392, 'support': 1047}}\n",
      "0.9398280802292264\n",
      "0.9671704012506515\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "validation_loader = DataLoader(eval_dataset)\n",
    "\n",
    "preds, tot_labels, confidences = evaluate(model, tokenizer, validation_loader)\n",
    "tot_labels = np.array(tot_labels)\n",
    "preds = np.array(preds)\n",
    "confidences = np.array(confidences)\n",
    "report = classification_report(tot_labels, preds, target_names=[\"Not PCL\", \"PCL\"], output_dict=True)\n",
    "print(report)\n",
    "\n",
    "print(report['accuracy'])\n",
    "print(report['Not PCL']['f1-score'])\n",
    "print(report['PCL']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1940618e-03],\n",
       "       [4.1436334e-04],\n",
       "       [3.1022815e-04],\n",
       "       ...,\n",
       "       [3.2770116e-04],\n",
       "       [8.5414242e-05],\n",
       "       [3.8479487e-04]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# define threshold\n",
    "pcl_count_by_threshold = []\n",
    "non_pcl_count_by_threshold = []\n",
    "f1_by_threshold = []\n",
    "for percentage in range(100):\n",
    "    threshold = percentage / 100\n",
    "    pcl_count = (confidences > threshold).sum()\n",
    "    non_pcl_count = (confidences <= threshold).sum()\n",
    "    pred = np.zeros(tot_labels.shape)\n",
    "    pred[confidences > threshold] = 1\n",
    "    pcl_count_by_threshold.append(pcl_count)\n",
    "    non_pcl_count_by_threshold.append(non_pcl_count)\n",
    "    f1_by_threshold.append(classification_report(tot_labels, pred, target_names=[\"Not PCL\", \"PCL\"], output_dict=True)['PCL']['f1-score'])\n",
    "\n",
    "best_threshold = np.argmax(f1_by_threshold) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408839779005524"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_threshold\n",
    "np.max(f1_by_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcZklEQVR4nO3deZxU5Z3v8c/PZlNkUcBEFoFckaFFLtItirgggoobohIhuKGGkQmDJDPxot6JKyQGV/IiTrhqRkWDEQ3icnWMmkGMURt3YUwIIDRBaQniAthd8Js/nmq6qru6qe6uovuc/r5fr3pVn1On6vyOp/3y9FPPeY65OyIiEn37NHUBIiKSGwp0EZGYUKCLiMSEAl1EJCYU6CIiMdGqqXbctWtX79OnT1PtXkQkkpYvX/6Zu3fL9FqTBXqfPn0oKSlpqt2LiESSmX1c22vqchERiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJppsHHpLs3IlLFoEFRXZv6dVK7jkEujdO391VfriC3j5ZUgkwnLnzjByJJjlf9/N0fbtsHFj/d5z4IHhv5tIU1Gg50EiAZXTzH/wAcyeDY8/HtbVJyDd4b77YOnS/IX655/DL34Bd94JW7akv/bDH8Ltt7esUP/yS5g3D267DTZvrt9727WDp5+Gk0/OT20ie6JAz6Fdu0II/uIXVYEO0LEjXHcdXHUVdO2a/ee99VZoJZ98cgj17t3D8223wbp1ual5zZrQOj/7bJgxo6q++fNDyHfsCDfcUPN9a9fCv/97zX8EoiyRgCefDEE+ZgyMHw8FBdm91z2cl7Fj4aWXYOjQ/NYqkokCPUcSCbj8cnjwQbj4YjjssLC+c2eYNKlhf4oPGQLPPQejR4dQ79YNXnkFDjoIjjkmNy3noiL453+GwYPT1999N3z9Ndx4I+y3H1x2WVhfVhaC68EHw/67dGl8Dc3JMcfAv/0bHH10/d87ejQcf3z4x+CVV6CwMPf1idTJ3ZvkUVRU5HvDtm3ut9/u/tlnuf3cRMJ948bw2LDB/fzz3cH95pvdd+3K7b6WLnXfbz/3Hj3c584Nx7Q3JBLu48eH40p9tGvnPn26e2np3qkjSv76V/eDD3bv2NG9sDA8jj3W/YMPmroyiQugxGvJVfMmuqdocXGx53tyLne49NLQmrzySrjnnsZ/5rZtcP/9oZX6cbUpcu64I3S55ENZWej+aNs2P59fm/JyePRR2Lo1LLduHbpnDj5479YRJStWwE9/Cjt2hOWlS8MX3K++CppgVBrLzJa7e3HG1+Ic6HPnhn7r3r3hb3+DVavgkEMa9ll//3v4smzuXPjsMzj2WJgwIQQcQP/+cNJJuatd4uP99+GEE0KX2bJloctMpKHqCvRI96GXlcFvfgP/+I81W67/9V/wox+FL6nuvhv69Qutpmxa6R9/DKWl4eedO+GJJ+Dee0Of8umnwzXXwHHH5f54JJ6OOCKMfhk9Gk45Bc49N/f7GD5co2uEaPeh33df6NM95xz38vKq9e++696tm3v//u5bt4Z1U6e6t27t/vHHtX/ea6+5n3uuu1l6n3GrVu4XXeT+3nuNLllasGeece/QoeZ3Erl47LOP+5NPNvURyt5AHX3okW6hl5eH58WL4cIL4eGH4YEHYNo0OOCAsL5jx7DNNdeEVvZPfxqGFT7+eBh299ln4fUdO0KXTOfOYdsTT6waRTJgAPTsuZcPTmLn9NPDdxG57uX8+msYNQouuAD+8z/DSJuKCliwIFwslml/3/521QgmiY9IB3rlVY0zZ8LPfgbvvAN//nP45X744fS+yl694IorQqg/91wYR33ooTBoUHjdDH7wgzD0sEOHvX0k0lKY5f5CrQ4d4JlnQjfgWWfBtdeGxsqaNeHL6333rfmeNWvgo49Cd2KrSKeApKmt6Z7vRy66XO68M/y5uWWL++zZ7gUF7tdfH4bbZbJunXunTu7Dh7svXuy+c2ejSxBpNtauDUNbwf2oo9yfeqr2IbTz5oXtrrgi98NsJb+Ia5dLZQu9VavQTTJjRubWSKVevcJVgNle/ScSJb17h6GRa9akdxlm8k//FEZ+zZoV5qA577ya2+y3Hxx+eMua+iHqYhPoUHeYV1KYS5z17p39vD833xwmIPv5z8Mjk3/9V5gzJ3f1SX5FOtArZy5UH6BI/ZmFOXsuuihcMFfdE0+EC+h69YLp06vWv/de1WCChhgwQBem5UtWUWhmpwF3AwXAve7+swzbfBe4AXDgXXf/Xg7rzKiyha5Wt0jDFBTAiBGZXzv11NBFOWMG9OgR5u258Ub4wx8at89OneCPf9RcN/mwx0A3swJgHjAaKAXeNLMl7r4iZZt+wDXAcHffYmZ75Vq4RCL8QqqPTyT3CgrgkUfCBUvjx4fhj9/+dpjioqioYZ+5fXuYjuP00+G119RSz7VsWuhDgVXuvhrAzBYCY4EVKdt8H5jn7lsA3H1TrgvNJJFQd4tIPu27LyxZEq7tOO64MKw3m++q6vL002EqhDPPDFd0779/bmqV7AK9B7A+ZbkUqD656GEAZvYqoVvmBnd/LicV1kGBLpJ/XbvCwoW5+7yiIvjtb8Mkb0cdFbpzquvZM8ybVHlhoGQnV/cUbQX0A0YAE4H/Z2adq29kZlPMrMTMSsrKyhq900SianIsEYmOM86Ahx4K/1js2JH+2L49XOV6wQVV35NJdrJp324AeqUs90yuS1UKvO7uFcAaM/szIeDfTN3I3ecD8yHMttjQoiuphS4SXd/7XnhkMn9+mHRv2rSqCfWeeSYE/TffZL+PgoIwQueEExpfbxRkE4dvAv3MrC8hyCcA1U/DYkLL/Ndm1pXQBbM6h3VmpEAXiacpU2D1arj11rD8xhvw9tvhS9n6TD/8ySdhfps//hEGDsxPrc3JHuPQ3RNmNg14ntA/fr+7f2hmNxEuQV2SfO0UM1sB7AR+7O71vMVu/VVUKNBF4mr27HDV669+FeZd+vWvw+0c69PNWloa7u965pnw+uvwrW/lr97mINI3uLj44nDvxjVrclSUiDQr5eVheOPw4Q1vvC1fHrpcjjgizD7Z2FE6Ta2uG1zk6kvRJqEuF5F4a9MmzEvTmP/Pi4pC3/sbb8Dkybmfvrg5UaCLSOyNGxem2H70UbjppqauJn8U6CLSIvz4x3DJJXDDDSHYs7VyZZjv5rTTquaPaq4iHYcahy4i2TILX7CuXh2mH/jb36B9+9q3d4cXX4RFi0LOlJfDgw+Gq2Wbq8gHulroIpKttm3DLJLDh4ebyO9Jhw5V91o444ww5fBFF4W+/eYo0nGoQBeR+uraFd5/P7spgDt3rrrv6s03h26X++6DqVPzWmKDRToONQ5dRBqiTRvo3r1+7znllNCynzUrjJZp1y799U2b4Mknq/rZO3aE735377bmIx2H6kMXkb3FLLTSR44MffFXXRXWf/JJuKvTPfeEeWhSvfJK2HZv0SgXEZEsnXRSeFx9dWjhd+8ebvl3111hzvh334VPPw2Pq68Oc9LMn7/36ot0HCrQRWRvmzcvTO27c2dY7tQpTCR26KHp282eHW7XN21amEfm2GPzX1uk41CBLiJ724ABVTNA1qXyjk/FxXDeeaEVP3o0HHhg/mqLfJeL+tBFpLk64ABYvDj8PGECdOsWvlh99tn87C/yga4Wuog0Z0ccAevXw6uvwnXXhQuU8nXjjkjHoQJdRKKgVavQh37ssfmdSybSLXSNQxcRqRLpQFcLXUSkigJdRCQmFOgiIjER+UDXsEURkSDyga4WuohIoEAXEYkJBbqISExENtDdw+Q4CnQRkSCygV556awCXUQkUKCLiMSEAl1EJCYiH+gahy4iEkQ+0NVCFxEJFOgiIjER2UCvqAjPCnQRkSCyga4WuohIOgW6iEhMKNBFRGJCgS4iEhNZBbqZnWZmH5nZKjObmeH1S82szMzeST6uyH2p6TQOXUQk3R7bt2ZWAMwDRgOlwJtmtsTdV1Tb9FF3n5aHGjNSC11EJF02LfShwCp3X+3u5cBCYGx+y9ozBbqISLpsAr0HsD5luTS5rrrzzOw9M1tkZr0yfZCZTTGzEjMrKSsra0C5VTQOXUQkXa6+FH0K6OPug4AXgAcybeTu89292N2Lu3Xr1qgdqoUuIpIum0DfAKS2uHsm1+3m7pvd/Zvk4r1AUW7Kq50CXUQkXTaB/ibQz8z6mlkbYAKwJHUDMzs4ZfFsYGXuSsxMgS4ikm6PcejuCTObBjwPFAD3u/uHZnYTUOLuS4DpZnY2kAD+Dlyax5oBBbqISHVZxaG7Pws8W23dT1J+vga4Jrel1U3j0EVE0ulKURGRmFCgi4jERGQDXePQRUTSRTbQ1UIXEUmnQBcRiQkFuohITEQ+0DVsUUQkiHygq4UuIhIo0EVEYkKBLiISE5EN9Mpx6AUFTVuHiEhzEdlATyRCmJs1dSUiIs1DpANd3S0iIlUU6CIiMRHpQNcYdBGRKpEOdLXQRUSqKNBFRGJCgS4iEhORDfSKCgW6iEiqyAa6WugiIukU6CIiMaFAFxGJiUgHusahi4hUiXSgq4UuIlJFgS4iEhMKdBGRmIhsoGscuohIusgGulroIiLpFOgiIjGhQBcRiYlIB7rGoYuIVIl0oKuFLiJSRYEuIhITWQW6mZ1mZh+Z2Sozm1nHdueZmZtZce5KzEyBLiKSbo+BbmYFwDxgDFAITDSzwgzbdQCuAl7PdZGZaBy6iEi6bFroQ4FV7r7a3cuBhcDYDNvdDNwK7MhhfbVSC11EJF02gd4DWJ+yXJpct5uZDQF6ufszdX2QmU0xsxIzKykrK6t3sakU6CIi6Rr9paiZ7QPcAfzLnrZ19/nuXuzuxd26dWvUfhXoIiLpsgn0DUCvlOWeyXWVOgADgT+Y2VrgGGBJvr8Y1Th0EZF02QT6m0A/M+trZm2ACcCSyhfdfau7d3X3Pu7eB/gTcLa7l+Sl4iS10EVE0u0x0N09AUwDngdWAr919w/N7CYzOzvfBdZGgS4iki6rSHT3Z4Fnq637SS3bjmh8WXuqB3buVKCLiKSK5JWiiUR4VqCLiFRRoIuIxIQCXUQkJiId6Bq2KCJSJdKBrha6iEgVBbqISEwo0EVEYkKBLiISE5EM9IqK8KxAFxGpEslAVwtdRKQmBbqISExEOtA1Dl1EpEqkA10tdBGRKgp0EZGYUKCLiMSEAl1EJCYiGegahy4iUlMkA10tdBGRmhToIiIxEelA1zh0EZEqkQ50tdBFRKoo0EVEYkKBLiISEwp0EZGYiGSgaxy6iEhNkQx0tdBFRGpSoIuIxESkA13j0EVEqkQ60NVCFxGpokAXEYmJSAd6QUHT1iEi0pxENtALCsCsqSsREWk+IhnoFRXqbhERqS6rQDez08zsIzNbZWYzM7x+pZm9b2bvmNkyMyvMfalVEgkFuohIdXsMdDMrAOYBY4BCYGKGwH7E3Y9w98HAz4E7cl1oKgW6iEhN2bTQhwKr3H21u5cDC4GxqRu4+xcpi+0Bz12JNSUSGoMuIlJdNu3cHsD6lOVS4OjqG5nZD4AfAW2AkZk+yMymAFMADjnkkPrWupta6CIiNeXsS1F3n+fu/wv4P8D/rWWb+e5e7O7F3bp1a/C+FOgiIjVlE+gbgF4pyz2T62qzEDinETXtkQJdRKSmbAL9TaCfmfU1szbABGBJ6gZm1i9l8QzgL7krsSYFuohITXuMRXdPmNk04HmgALjf3T80s5uAEndfAkwzs1FABbAFuCSfRWscuohITVnFors/Czxbbd1PUn6+Ksd11UktdBGRmiJ5paiGLYqI1BTZQFcLXUQknQJdRCQmFOgiIjGhQBcRiYlIBrqGLYqI1BTJQFcLXUSkJgW6iEhMRDbQNQ5dRCRdZANdLXQRkXQKdBGRmFCgi4jEhAJdRCQmIhnoGocuIlJTJANdLXQRkZoU6CIiMRHZQNc4dBGRdJENdLXQRUTSKdBFRGIicoHuDjt3KtBFRKqLXKDv3BmeFegiIukiF+gVFeFZgS4iki5ygZ5IhGcFuohIOgW6iEhMRDbQNQ5dRCRdZANdLXQRkXQKdBGRmFCgi4jEhAJdRCQmIhfoGocuIpJZ5AJdLXQRkcwiG+gatigiki6yga4WuohIuqwC3cxOM7OPzGyVmc3M8PqPzGyFmb1nZi+aWe/clxoo0EVEMttjLJpZATAPGA2UAm+a2RJ3X5Gy2dtAsbtvM7OpwM+BC/JRsAJdpG4VFRWUlpayY8eOpi5FGqFdu3b07NmT1vXoX84mFocCq9x9NYCZLQTGArsD3d1fTtn+T8CFWVdQTwp0kbqVlpbSoUMH+vTpg5k1dTnSAO7O5s2bKS0tpW/fvlm/L5sulx7A+pTl0uS62lwO/P9ML5jZFDMrMbOSsrKyrItMpUAXqduOHTvo0qWLwjzCzIwuXbrU+6+snH4pamYXAsXAnEyvu/t8dy929+Ju3bo1aB8ahy6yZwrz6GvIOcwmFjcAvVKWeybXVd/5KOA64ER3/6belWRJLXQRkcyyaaG/CfQzs75m1gaYACxJ3cDMjgR+BZzt7ptyX2YVjUMXEclsj4Hu7glgGvA8sBL4rbt/aGY3mdnZyc3mAPsDj5nZO2a2pJaPazS10EWav7lz5zJgwADOO+88hg0bRtu2bbntttvqfM/atWsZOHBgo/c9e/bsnH9mdTfccMMej6e6/fffP+P6Sy+9lEWLFuWirKy6XHD3Z4Fnq637ScrPo3JSTRYU6CLZmzED3nknt585eDDcdVfd2/zyl7/k97//PW3atOHjjz9m8eLFuS2iDrNnz+baa6+t13sSiQStYhAqulJURHLqyiuvZPXq1YwZM4aHH36Yo446Kuux1IlEgkmTJjFgwADOP/98tm3bxksvvcQ555yze5sXXniBcePGZXz/zJkz2b59O4MHD2bSpEkA7Ny5k+9///scfvjhnHLKKWzfvh2AESNGMGPGDIqLi7n77rtZvnw5J554IkVFRZx66qls3LgRCH9tFBYWMmjQICZMmLB7XytWrGDEiBF85zvfYe7cubvX33HHHQwcOJCBAwdyV4Z/+dydadOm0b9/f0aNGsWmTTnspXb3JnkUFRV5Q9x7rzu4r1vXoLeLxN6KFSuaugTv3bu3l5WV7V6+/vrrfc6cOXW+Z82aNQ74smXL3N198uTJPmfOHN+1a5f379/fN23a5O7uEydO9CVLltT6Oe3bt0/7zIKCAn/77bfd3X38+PH+0EMPubv7iSee6FOnTnV39/Lych82bNjufSxcuNAnT57s7u4HH3yw79ixw93dt2zZsvt4hg0b5jt27PCysjI/8MADvby83EtKSnzgwIH+1Vdf+ZdffumFhYX+1ltvpdX1+OOP+6hRozyRSPiGDRu8U6dO/thjj2U8lkznEijxWnJVLXQRaTZ69erF8OHDAbjwwgtZtmwZZsZFF13EggUL+Pzzz3nttdcYM2ZM1p/Zt29fBg8eDEBRURFr167d/doFF4QL2j/66CM++OADRo8ezeDBg7nlllsoLS0FYNCgQUyaNIkFCxakdcucccYZtG3blq5du3LQQQfx6aefsmzZMsaNG0f79u3Zf//9Offcc3nllVfS6lm6dCkTJ06koKCA7t27M3LkyIb8p8oocrGocegi8VV97HXl8uTJkznrrLNo164d48ePr1d/d9u2bXf/XFBQsLvLBaB9+/ZA6Kk4/PDDee2112q8/5lnnmHp0qU89dRTzJo1i/fffz/j5yYqW5tNSC10EWk21q1btztUH3nkEY477jgAunfvTvfu3bnllluYPHlynZ/RunVrKipbflnq378/ZWVlu/ddUVHBhx9+yK5du1i/fj0nnXQSt956K1u3buWrr76q9XOOP/54Fi9ezLZt2/j666/53e9+x/HHH5+2zQknnMCjjz7Kzp072bhxIy+//HItn1Z/kYtFjUMXiY5PPvmE4uJivvjiC/bZZx/uuusuVqxYQceOHTNu379/f+bNm8dll11GYWEhU6dO3f3apEmTKCsrY8CAAXXuc8qUKQwaNIghQ4Ywa9asrOps06YNixYtYvr06WzdupVEIsGMGTM47LDDuPDCC9m6dSvuzvTp0+ncuXOtnzNkyBAuvfRShg4dCsAVV1zBkUcembbNuHHjeOmllygsLOSQQw5h2LBhWdWYDQt97HtfcXGxl5SU1Pt9Tz4JCxaER8pfPCKStHLlyj2GXhRNmzaNI488kssvv7ypS9lrMp1LM1vu7sWZto9cC33s2PAQkZajqKiI9u3bc/vttzd1Kc1a5AJdRKJt8+bNnHzyyTXWv/jii3Tp0iXje5YvX15j3dFHH80336RPG/XQQw9xxBFH5KbQCFKgi8SQuzfbGRe7dOnCOzm4fPX1119vfDHNWEO6wyM3ykVE6tauXTs2b97coECQ5sGTN7ho165dvd6nFrpIzPTs2ZPS0lIaehMZaR4qb0FXHwp0kZhp3bp1vW5bJvGhLhcRkZhQoIuIxIQCXUQkJprsSlEzKwM+buDbuwKf5bCcqGiJx90Sjxla5nG3xGOG+h93b3fvlumFJgv0xjCzktoufY2zlnjcLfGYoWUed0s8ZsjtcavLRUQkJhToIiIxEdVAn9/UBTSRlnjcLfGYoWUed0s8ZsjhcUeyD11ERGqKagtdRESqUaCLiMRE5ALdzE4zs4/MbJWZzWzqevLBzHqZ2ctmtsLMPjSzq5LrDzSzF8zsL8nnA5q61lwzswIze9vMnk4u9zWz15Pn+1Eza9PUNeaamXU2s0Vm9t9mttLMhrWQc/3D5O/3B2b2GzNrF7fzbWb3m9kmM/sgZV3Gc2vB3OSxv2dmQ+q7v0gFupkVAPOAMUAhMNHMCpu2qrxIAP/i7oXAMcAPksc5E3jR3fsBLyaX4+YqYGXK8q3Ane5+KLAFiOP9x+4GnnP3fwD+N+H4Y32uzawHMB0odveBQAEwgfid7/8ATqu2rrZzOwbol3xMAe6p784iFejAUGCVu69293JgIRC7G9K5+0Z3fyv585eE/8F7EI71geRmDwDnNEmBeWJmPYEzgHuTywaMBBYlN4njMXcCTgDuA3D3cnf/nJif66RWwL5m1grYD9hIzM63uy8F/l5tdW3ndizwoAd/Ajqb2cH12V/UAr0HsD5luTS5LrbMrA9wJPA68C1335h86RPgW01VV57cBVwN7EoudwE+d/dEcjmO57svUAb8OtnVdK+ZtSfm59rdNwC3AesIQb4VWE78zzfUfm4bnW9RC/QWxcz2Bx4HZrj7F6mveRhvGpsxp2Z2JrDJ3WvePDLeWgFDgHvc/Ujga6p1r8TtXAMk+43HEv5B6w60p2bXROzl+txGLdA3AL1Slnsm18WOmbUmhPnD7v5EcvWnlX+CJZ83NVV9eTAcONvM1hK60kYS+pY7J/8kh3ie71Kg1N0rb5C5iBDwcT7XAKOANe5e5u4VwBOE34G4n2+o/dw2Ot+iFuhvAv2S34S3IXyJsqSJa8q5ZN/xfcBKd78j5aUlwCXJny8BntzbteWLu1/j7j3dvQ/hvL7k7pOAl4Hzk5vF6pgB3P0TYL2Z9U+uOhlYQYzPddI64Bgz2y/5+1553LE+30m1ndslwMXJ0S7HAFtTumay4+6RegCnA38G/gpc19T15OkYjyP8GfYe8E7ycTqhT/lF4C/A74EDm7rWPB3/CODp5M/fAd4AVgGPAW2bur48HO9goCR5vhcDB7SEcw3cCPw38AHwENA2bucb+A3hO4IKwl9jl9d2bgEjjOL7K/A+YQRQvfanS/9FRGIial0uIiJSCwW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgi4jEhAJdRCQm/gcA+dhHf8A7pgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=np.arange(0,100)\n",
    "l1=plt.plot(x,pcl_count_by_threshold,'r',label='pcl_count_by_threshold')\n",
    "l2=plt.plot(x,non_pcl_count_by_threshold,'g',label='non_pcl_count_by_threshold')\n",
    "\n",
    "# plt.plot(x1,y1,'ro-',x2,y2,'g+-',x3,y3,'b^-')\n",
    "plt.title('The Lasers in Three Conditions')\n",
    "plt.xlabel('thkreshold')\n",
    "plt.ylabel('column')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "l3=plt.plot(x, f1_by_threshold,'b',label='f1_by_threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760/1932561778.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = nn.functional.softmax(logits)[: , 1].cpu()\n"
     ]
    }
   ],
   "source": [
    "dpm_pp.load_test()\n",
    "test_df = dpm_pp.test_set_df\n",
    "test_df['label'] = 0\n",
    "test_dataset = PCLDataset(tokenizer, test_df)\n",
    "\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "preds, tot_labels, confidences = evaluate(model, tokenizer, test_loader, best_threshold)\n",
    "tot_labels = np.array(tot_labels)\n",
    "preds = np.array(preds)\n",
    "# report = classification_report(tot_labels, preds, target_names=[\"Not PCL\",\"PCL\"], output_dict= True)\n",
    "# print(report)\n",
    "\n",
    "# print(report['accuracy'])\n",
    "# print(report['Not PCL']['f1-score'])\n",
    "# print(report['PCL']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3832, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds.shape\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3579, 1: 253})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "preds = preds.reshape(-1)\n",
    "Counter(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "\twith open(outf_path,'w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "updating: task1.txt (deflated 95%)\n"
     ]
    }
   ],
   "source": [
    "labels2file([[k] for k in preds], 'task1.txt')\n",
    "!cat task1.txt | head -n 10\n",
    "!zip submission.zip task1.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
