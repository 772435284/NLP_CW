{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.66)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dpm_preprocessing import DPMProprocessed\n",
    "import torch\n",
    "# from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments, RobertaConfig\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model_name = \"microsoft/deberta-v2-xlarge\"\n",
    "model_path = f'./models5e6/pcl_{model_name}_finetuned/model/'\n",
    "tokenizer_path = f'./models5e6/pcl_{model_name}_finetuned/tokenizer/'\n",
    "MAX_SEQ_LEN = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map of label to numerical label:\n",
      "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n",
      "      par_id      art_id     keyword country  \\\n",
      "0          1  @@24942188    hopeless      ph   \n",
      "1          2  @@21968160     migrant      gh   \n",
      "2          3  @@16584954   immigrant      ie   \n",
      "3          4   @@7811231    disabled      nz   \n",
      "4          5   @@1494111     refugee      ca   \n",
      "...      ...         ...         ...     ...   \n",
      "10464  10465  @@14297363       women      lk   \n",
      "10465  10466  @@70091353  vulnerable      ph   \n",
      "10466  10467  @@20282330     in-need      ng   \n",
      "10467  10468  @@16753236    hopeless      in   \n",
      "10468  10469  @@16779383    homeless      ie   \n",
      "\n",
      "                                                    text  label orig_label  \\\n",
      "0      We are living in times of absolute insanity , ...      0          0   \n",
      "1      In Libya today , there are countless number of...      0          0   \n",
      "2       White House press secretary Sean Spicer said ...      0          0   \n",
      "3      Council customers only signs would be displaye...      0          0   \n",
      "4       Just like we received migrants fleeing El Sal...      0          0   \n",
      "...                                                  ...    ...        ...   \n",
      "10464   Sri Lankan norms and culture inhibit women fr...      0          1   \n",
      "10465  He added that the AFP will continue to bank on...      0          0   \n",
      "10466   She has one huge platform , and information c...      1          3   \n",
      "10467   Anja Ringgren Loven I ca n't find a word to d...      1          4   \n",
      "10468   Guinness World Record of 540lbs of 7 layer mu...      1          3   \n",
      "\n",
      "       lenght  \n",
      "0         123  \n",
      "1          41  \n",
      "2          25  \n",
      "3          30  \n",
      "4          51  \n",
      "...       ...  \n",
      "10464      62  \n",
      "10465      42  \n",
      "10466      54  \n",
      "10467     103  \n",
      "10468      29  \n",
      "\n",
      "[10469 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from dpm_preprocessing import DPMProprocessed\n",
    "\n",
    "dpm_pp = DPMProprocessed('.', 'task4_test.tsv')\n",
    "\n",
    "\n",
    "train_df_path = 'traindf_backtrans.pickle'\n",
    "val_df_path = 'valdf_backtrans.pickle'\n",
    "\n",
    "train_df = pd.read_pickle(train_df_path)\n",
    "val_df = pd.read_pickle(val_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_split_orig = [] \n",
    "for i in range(5):\n",
    "    val_df_split_orig.append(val_df[val_df['orig_label'] == str(i)]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1536, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (12): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (13): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (14): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (15): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (16): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (17): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (18): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (19): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (20): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (21): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (22): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (23): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1536)\n",
       "      (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "      (conv): ConvLayer(\n",
       "        (conv): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (LayerNorm): LayerNorm((1536,), eps=1e-07, elementwise_affine=True)\n",
       "        (dropout): StableDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=1536, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_df_item(text):\n",
    "    with torch.no_grad():  \n",
    "        encodings = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=MAX_SEQ_LEN)\n",
    "        output = model(**encodings)\n",
    "        logits = output.logits\n",
    "        prob = nn.functional.softmax(logits)[:, 1]\n",
    "        return prob.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14807/3751858083.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = nn.functional.softmax(logits)[:, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(val_df))\n",
    "val_df['prob_pcl'] = val_df['text'].map(evaluate_df_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_pickle('val_df_prob_pcl.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_split_orig = [] \n",
    "for i in range(5):\n",
    "    val_df_split_orig.append(val_df[val_df['orig_label'] == str(i)]['prob_pcl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01658866228185835, 0.18068804588179027, 0.46519472676883805, 0.5036295687072931, 0.778287201171568]\n",
      "[0.12326203253335281, 0.37882583652541324, 0.48192378145185183, 0.48192189207433733, 0.3927292466136566]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(5,3.5))\n",
    "x = np.array([0, 1, 2, 3, 4])\n",
    "y = [val_df_split_orig_i.mean() for val_df_split_orig_i in val_df_split_orig ] # Effectively y = x**2\n",
    "#e = [np.std()])\n",
    "e = [val_df_split_orig_i.std() for val_df_split_orig_i in val_df_split_orig ] \n",
    "plt.title('PCL detection per orig_label')\n",
    "plt.xticks(np.arange(5)) \n",
    "\n",
    "plt.errorbar(x, y, e, linestyle='None', marker='^')\n",
    "print(y)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {\n",
    "\t\t\t\t'Unbalanced_power_relations':0,\n",
    "\t\t\t\t'Shallow_solution':1,\n",
    "\t\t\t\t'Presupposition':2,\n",
    "\t\t\t\t'Authority_voice':3,\n",
    "\t\t\t\t'Metaphors':4,\n",
    "\t\t\t\t'Compassion':5,\n",
    "\t\t\t\t'The_poorer_the_merrier':6\n",
    "\t\t\t\t}\n",
    "                \n",
    "\n",
    "par_id_val = val_df['par_id'].tolist()\n",
    "\n",
    "val_task2 = dpm_pp.train_task2_df.drop(dpm_pp.train_task2_df[dpm_pp.train_task2_df['par_id'].map(lambda id: (id not in par_id_val) )].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
      "/tmp/ipykernel_14807/2846639392.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n"
     ]
    }
   ],
   "source": [
    "val_df_split_cat = []\n",
    "for i in range(7):\n",
    "    cat_df = val_task2[val_task2['label'].map(lambda label: bool(label[i]))]\n",
    "    cat_df['prob_pcl'] = cat_df['par_id'].map(lambda pid: val_df[val_df['par_id'] == pid]['prob_pcl'].values)\n",
    "    val_df_split_cat.append(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5, 6])\n",
    "plt.figure(figsize=(5,3.5))\n",
    "y = [val_df_split_cat_i['prob_pcl'].mean() for val_df_split_cat_i in val_df_split_cat ] \n",
    "#e = [np.std()])\n",
    "e = [val_df_split_cat_i['prob_pcl'].std() for val_df_split_cat_i in val_df_split_cat ] \n",
    "plt.title('PCL detection per category')\n",
    "plt.errorbar(x, y, e, linestyle='None', marker='^')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
